<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport"
          content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta name="viewport"
          content="width=device-width, user-scalable=yes, initial-scale=1.0, maximum-scale=3.0, minimum-scale=1.0">
    <meta http-equiv="Content-Language" content="en">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <title>pytorch dynamo 介绍</title>
    <meta name="description" content="Blog of a Software Engineer"/>
    <meta name="keywords" content="blog,developer blog,engineering blog"/>

    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Alegreya:400,400i|Lato:400,400i,700,900|Roboto+Mono:400,300">
    <link rel="stylesheet"
          href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/shades-of-purple.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>

    <script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML">
    </script>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true},
        jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
        extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
        TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
        equationNumbers: {
        autoNumber: "AMS"
        }
        }
    });
    </script>

    <link rel="stylesheet" href="/css/normalize.css"/>
    <link rel="stylesheet" href="/css/theme.css"/>
</head>
<body>
<nav class="nav">
    <div class="nav__left">
        <a href="/">Home</a>
        <a href="/about">About</a>
    </div>
    <div class="nav__right">
        <a target="_blank" href="https://github.com/turingki" class="link-github">GitHub</a>
        <a target="_blank" href="https://twitter.com/mxlol233" class="link-twitter">Twitter</a>
        <a href="mailto:mxlol233@outlook.com" class="link-email">Email</a>
    </div>
</nav>

<article class="mar-b-7">
    <header class="text-center">
        <time class="mar-b-6" datetime="Fri, February 03, 2023">Fri, February 03, 2023</time>
        <h1 class="mar-b-7">pytorch dynamo 介绍</h1>
    </header>
    <h1 id="">介绍</h1>
<p>Dynamo在不牺牲Python用户体验的情况下，适时地寻找优化的机会。</p>
<p>dynamo在Python字节码执行前对其进行动态修改。它重写Python字节码，以便将PyTorch操作的序列提取到FX Graph中，然后用不同的后端和自动调整的组合进行及时编译。它通过字节码分析来创建这个FX Graph，旨在生成子图，可以与Python的执行相混合，以获得两个世界的最佳效果：可用性和性能。</p>
<p>这里要强调的是，pytorch为了保证不破坏eager模式，不会介意把一个完整的大图切成小图分别编译。</p>
<p>从硬件的角度考虑，我们当然希望数据留在device上的时间越长越好，即不要切分子图，尽量保证模型能用少量的大图表示。留的越久，给硬件厂商程序员优化的机会就越多。但是上层算法应用的工程师不会这么想问题，除非他特别了解你的硬件，或者你的硬件在市场是有着极高的占有率。</p>
<p>PyTorch的图建立过程是基于tracing的，因为pytorch一开始是一个eager的框架，然后在一些东西上添加了图的东西。tracing是重用已有的eager代码的最简单方法。很明显，MLIR是从另一端来的，这也是有效的，但它处于在权衡曲线的另一端。</p>
<p>基于mlir的层级转换方式，总是在丢失原本的信息。最终使得编译表示与原始训练脚本彻底解耦。这一过程也彻底与整个基于pytorch的算法生态链失去联系。同时，这里一个比较关键的问题是，mlir的方式似乎并没有给出一个完美的动态图编译的方案。自动梯度求导也是一个大问题。pytorch的编译做法与之相反：要完整的保留算法实现，即在不对原始表达方式做任何外部更改的情况下产生编译结果。</p>
<h1 id="graph">Graph</h1>
<p>对于一个图，我们关心它的三个部分：</p>
<ul>
<li>输入；</li>
<li>图中的操作；</li>
<li>输出；</li>
</ul>
<p>这三个部分都可以用节点（Node）来表示。</p>
<h2 id="node">Node的创建过程</h2>
<p><img src="imgs/dynamo/Untitled.png" alt="Untitled" /></p>
<p>那么transform<em>code</em>object的输入参数之一，code，是从哪里来的呢？</p>
<h2 id="code">code的来源</h2>
<p>dynamo的context通过在python解释过程中设置回调函数，来修改原始的比特码。</p>
<p><img src="imgs/dynamo/Untitled%201.png" alt="Untitled" /></p>
<p>code是eval_frame的回调函数的输入参数，是python解释器提供给它的。</p>
<h3 id="-1">回调函数设置的实现过程</h3>
<p>dynamo通过调用set<em>eval</em>frame接口来设置回调函数。</p>
<p><img src="imgs/dynamo/Untitled%202.png" alt="Untitled" /></p>
<p>它的实现在torch/csrc/dynamo/eval<em>frame.c中。调用关系为：set</em>eval<em>frame</em>py → set<em>eval</em>frame。</p>
<p><img src="imgs/dynamo/Untitled%203.png" alt="Untitled" /></p>
<p><img src="imgs/dynamo/Untitled%204.png" alt="Untitled" /></p>
<p><img src="imgs/dynamo/Untitled%205.png" alt="Untitled" /></p>
<p>enable<em>eval</em>frame<em>shim 将当前PyThreadState的eval</em>frame的入口设置为custom<em>eval</em>frame_shim。</p>
<p>eval<em>frame</em>callback_set会调用cpython的api：</p>
<p><img src="imgs/dynamo/Untitled%206.png" alt="Untitled" /></p>
<p>来设置Thread Specific Storage (TSS) 中存储的值。这是为了将回调函数保存在当前线程的全局存储位置。</p>
<h3 id="-2">线程本地存储</h3>
<p>线程本地存储（TLS）使用线程本地的静态或全局内存。</p>
<p>虽然在现代编程中一般不鼓励使用全局变量，但UNIX等传统操作系统是为单处理器硬件设计的，需要一些额外的机制来保留冗余前API的语义。这种情况的一个例子是，函数使用一个全局变量来设置错误条件（例如，C库的许多函数使用的全局变量errno）。如果errno是一个全局变量，一个线程上的系统函数的调用可能会覆盖先前由不同线程上的系统函数的调用所设置的值，可能在不同线程上的后续代码能够检查错误条件之前。解决方案是让errno成为一个看起来像全局的变量，但实际上每个线程只存在一次，也就是说，它生活在线程的本地存储中。第二个用例是多个线程将信息累积到一个全局变量中。为了避免出现竞赛条件，对这个全局变量的每一次访问都必须由一个突变器来保护。或者，每个线程可以将信息积累到一个线程本地变量中（根据定义，不能从其他线程中读取或写入，这意味着不可能存在竞赛条件）。然后，线程只需将自己的线程本地变量的最终积累同步到一个真正的全局变量中。</p>
<p>许多系统对线程本地内存块的大小进行了限制，事实上通常是相当严格的限制。另一方面，如果一个系统能够提供至少一个内存地址（指针）大小的线程本地变量，那么这就允许以线程本地的方式使用任意大小的内存块，方法是动态分配这样一个内存块，并将该内存块的内存地址存储在线程本地变量中。在RISC机器上，调用惯例常常为这种使用保留一个线程指针寄存器。</p>
<h3 id="threadspecificstoragetss">Thread Specific Storage (TSS)</h3>
<p>在python中，TSS的出现是为了解决TLS值的键的类型（int）问题。这是由最初的PyThread TLS API定义的。</p>
<p>最初的TLS API是由GvR在1997年添加到Python中的，当时用来表示TLS值的键是一个int，一直到写这篇文章时都是如此。这使用了CPython自己的TLS实现，该实现在Python/thread.c中长期未被使用，基本上没有变化。</p>
<p>选择int来表示TLS密钥的问题在于，虽然它对CPython自己的TLS实现来说是很好的，而且恰好与Windows兼容（Windows使用DWORD来表示类似的数据），但它与POSIX标准的pthreads API不兼容，该标准将pthread<em>key</em>t定义为一个不透明的类型，没有被标准进一步定义（如上面描述的Py<em>tss</em>t） 。这使得底层实现可以决定如何使用pthread<em>key</em>t的值来查询线程特定的数据。</p>
<p>对于Python的API来说，这通常不是一个问题，因为在Linux上pthread<em>key</em>t刚好被定义为无符号的int，所以与Python的TLS API完全兼容--由pthread<em>create</em>key创建的thread<em>key</em>t可以自由地转换为int并返回（好吧，不完全是，正如问题#22206所指出的，即使这样也有一些局限）。</p>
<p>然而，至少有一些平台（即Cygwin、CloudABI，但也可能有其他平台）有其他现代的、符合POSIX标准的pthreads实现，但与Python的API不兼容，因为它们的pthread<em>key</em>t的定义方式不能安全地投到int。事实上，在加入pthreads TLS的时候，MvL就提出了遇到这个问题的可能性。</p>
<p><img src="imgs/dynamo/Untitled%207.png" alt="Untitled" /></p>
<p>上图中执行fn的过程，即是用回调函数处理原始bytecode的过程。</p>
<h2 id="code-1">code的转换</h2>
<p>对于一段pytorch代码：</p>
<pre><code class="python language-python">def f(src,index):
    return torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)
</code></pre>
<p>下图展示了python解析出的bytecode。</p>
<p><img src="imgs/dynamo/Untitled%208.png" alt="Untitled" /></p>
<h3 id="srcindex">输入参数src, index的转换</h3>
<p>输入参数存放在frame.f<em>locals中，在回调函数执行编译过程的时候传递给</em>compile函数。</p>
<p><img src="imgs/dynamo/Untitled%209.png" alt="Untitled" /></p>
<p><img src="imgs/dynamo/Untitled%2010.png" alt="Untitled" /></p>
<p>它们会被VariableBuilder加工为symbolics。</p>
<p><img src="imgs/dynamo/Untitled%2011.png" alt="Untitled" /></p>
<p>它会根据f_locals的类型，生成不同的symbolics。</p>
<p><img src="imgs/dynamo/Untitled%2012.png" alt="Untitled" /></p>
<p>在这一过程中，会向graph中添加node。</p>
<p><img src="imgs/dynamo/Untitled%2013.png" alt="Untitled" /></p>
<h3 id="bytecode">bytecode的转换</h3>
<p>转换过程发生在IntructionTranslator.run中。</p>
<p><img src="imgs/dynamo/Untitled%2014.png" alt="Untitled" /></p>
<p>具体地，每次执行step时处理一条bytecode指令。</p>
<p><img src="imgs/dynamo/Untitled%2015.png" alt="Untitled" /></p>
<h3 id="return_value">RETURN_VALUE触发子图编译</h3>
<p>当step解析到RETURN_VALUE指令时，会根据之前收集到的图信息，做一次子图编译。</p>
<p><img src="imgs/dynamo/Untitled%2016.png" alt="Untitled" /></p>
<p><img src="imgs/dynamo/Untitled%2017.png" alt="Untitled" /></p>
<p>可以理解为：dynmao的攒图过程一直持续到当前函数返回，或者说当前栈帧执行结束。</p>
</article>


    <section id="mc_embed_signup" class="mar-tb-7 twitter-signup">
        <div class="mc-title-container"></div>

        <p class="mar-0 twitter-signup-text">👋 <a href="http://twitter.com/mxlol233"
                                                   target="_blank">Follow me on
                twitter</a> for the updates. </p>
    </section>


<footer class="text-center mar-tb-6">
    © 2023 mxlol233, unless otherwise stated.
</footer>

<script>hljs.highlightAll();</script>
</body>
</html>

